{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":866953,"sourceType":"datasetVersion","datasetId":430832}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Step 1: Imports & Setup**","metadata":{}},{"cell_type":"code","source":"import os, random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications import VGG16, MobileNetV2, EfficientNetB0, EfficientNetB3, ResNet50V2\n\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:54:57.196015Z","iopub.execute_input":"2025-10-15T15:54:57.196879Z","iopub.status.idle":"2025-10-15T15:55:13.357940Z","shell.execute_reply.started":"2025-10-15T15:54:57.196848Z","shell.execute_reply":"2025-10-15T15:55:13.357161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 2: Dataset Paths**","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/pothole-detection-dataset'\nimg_height, img_width = 224, 224\nbatch_size = 16\nnum_classes = 2\nseed = 42\n\n# reproducibility\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:55:51.204886Z","iopub.execute_input":"2025-10-15T15:55:51.205237Z","iopub.status.idle":"2025-10-15T15:55:51.210668Z","shell.execute_reply.started":"2025-10-15T15:55:51.205214Z","shell.execute_reply":"2025-10-15T15:55:51.209636Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 3: Count Images & Visualization**","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\n\n# Correct paths\nnormal_path = os.path.join(data_dir, \"normal\")\npotholes_path = os.path.join(data_dir, \"potholes\")\n\n# Count images\nnormal_imgs = glob(os.path.join(normal_path, '*.jpg'))\npothole_imgs = glob(os.path.join(potholes_path, '*.jpg'))\n\nprint(\"Normal images:\", len(normal_imgs))\nprint(\"Pothole images:\", len(pothole_imgs))\n\n# Pie chart\nlabels = ['Normal', 'Potholes']\nsizes = [len(normal_imgs), len(pothole_imgs)]\nif sum(sizes) > 0:   # avoid NaN error\n    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['skyblue','salmon'])\n    plt.title(\"Class Distribution\")\n    plt.show()\n\n    # Bar plot\n    sns.barplot(x=labels, y=sizes, palette='Set2')\n    plt.title(\"Class Distribution (Bar Plot)\")\n    plt.show()\nelse:\n    print(\"No images found. Double-check dataset format.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:55:53.678549Z","iopub.execute_input":"2025-10-15T15:55:53.678831Z","iopub.status.idle":"2025-10-15T15:55:54.043330Z","shell.execute_reply.started":"2025-10-15T15:55:53.678813Z","shell.execute_reply":"2025-10-15T15:55:54.042621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 4: Data Generators**","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    brightness_range=[0.8,1.2],\n    shear_range=0.1,\n    zoom_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\nval_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    seed=seed\n)\n\nval_generator = val_datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,   # important for matching preds <-> y_true\n    seed=seed\n)\n\n# compute class weights (helps if imbalance)\nclasses_array = train_generator.classes\ncw = class_weight.compute_class_weight('balanced', classes=np.unique(classes_array), y=classes_array)\nclass_weights = dict(enumerate(cw))\nprint(\"Class weights:\", class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:56:00.646754Z","iopub.execute_input":"2025-10-15T15:56:00.647101Z","iopub.status.idle":"2025-10-15T15:56:01.158213Z","shell.execute_reply.started":"2025-10-15T15:56:00.647065Z","shell.execute_reply":"2025-10-15T15:56:01.157476Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 5: Baseline CNN**","metadata":{}},{"cell_type":"code","source":"def make_baseline(input_shape=(img_height,img_width,3), num_classes=num_classes):\n    model = Sequential([\n        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n\n        Conv2D(64, (3,3), activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n\n        Conv2D(128, (3,3), activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n\n        Flatten(),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\nbaseline_model = make_baseline()\nbaseline_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\ncallbacks_common = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n]\n\nckpt_baseline = ModelCheckpoint('baseline_best.h5', monitor='val_accuracy', save_best_only=True, mode='max')\nhistory_baseline = baseline_model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=25,\n    callbacks=[ckpt_baseline] + callbacks_common,\n    class_weight=class_weights\n)\nbaseline_model.save(\"baseline_cnn_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:56:07.183518Z","iopub.execute_input":"2025-10-15T15:56:07.183899Z","iopub.status.idle":"2025-10-15T15:56:25.036199Z","shell.execute_reply.started":"2025-10-15T15:56:07.183876Z","shell.execute_reply":"2025-10-15T15:56:25.034884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 6: Transfer Learning**","metadata":{}},{"cell_type":"code","source":"def build_transfer_model(base_model, num_classes=num_classes):\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=preds)\n    return model, base_model\n\ndef train_model(model, base_model, name, initial_epochs=12, fine_tune_epochs=8, unfreeze_at=50):\n    # Phase 1: train top\n    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n    ckpt_1 = ModelCheckpoint(f'{name}_best.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n    h1 = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=initial_epochs,\n        callbacks=[ckpt_1] + callbacks_common,\n        class_weight=class_weights\n    )\n\n    # Phase 2: unfreeze some top layers of base_model and fine-tune\n    base_model.trainable = True\n    # freeze all but top `unfreeze_at` layers\n    if unfreeze_at > 0:\n        for layer in base_model.layers[:-unfreeze_at]:\n            layer.trainable = False\n\n    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    ckpt_ft = ModelCheckpoint(f'{name}_finetuned_best.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n    h2 = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=fine_tune_epochs,\n        callbacks=[ckpt_ft] + callbacks_common,\n        class_weight=class_weights\n    )\n    return h1, h2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T15:55:16.812757Z","iopub.execute_input":"2025-10-15T15:55:16.813286Z","iopub.status.idle":"2025-10-15T15:55:16.834375Z","shell.execute_reply.started":"2025-10-15T15:55:16.813260Z","shell.execute_reply":"2025-10-15T15:55:16.833156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 7: Train Transfer Models**","metadata":{}},{"cell_type":"code","source":"# VGG16\nvgg = VGG16(weights='imagenet', include_top=False, input_shape=(img_height,img_width,3))\nvgg_model, vgg_base = build_transfer_model(vgg)\nhistory_vgg, history_vgg_ft = train_model(vgg_model, vgg_base, \"vgg16_transfer_model\")\n\n# MobileNetV2\nmob = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height,img_width,3))\nmob_model, mob_base = build_transfer_model(mob)\nhistory_mob, history_mob_ft = train_model(mob_model, mob_base, \"mobilenetv2_transfer_model\")\n\n# EfficientNetB0\neff0 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height,img_width,3))\neff0_model, eff0_base = build_transfer_model(eff0)\nhistory_eff0, history_eff0_ft = train_model(eff0_model, eff0_base, \"efficientnetb0_transfer_model\")\n\n# # EfficientNetB3\n# eff3 = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(img_height,img_width,3))\n# eff3_model, eff3_base = build_transfer_model(eff3)\n# history_eff3, history_eff3_ft = train_model(eff3_model, eff3_base, \"efficientnetb3_transfer_model\")\n\n# ResNet50V2\nresnet_base = ResNet50V2(weights='imagenet', include_top=False, input_shape=(img_height,img_width,3))\nresnet_model, resnet_base = build_transfer_model(resnet_base)\nhistory_resnet, history_resnet_ft = train_model(resnet_model, resnet_base, \"resnet50v2_transfer_model\", initial_epochs=12, fine_tune_epochs=8, unfreeze_at=50)\n\n# # After training you can load the best finetuned model:\n# best_model_path = 'resnet50v2_transfer_model_finetuned_best.h5'  # saved by checkpoint naming above\n# if os.path.exists(best_model_path):\n#     best_model = load_model(best_model_path)\n# else:\n#     # fallback to last saved\n#     best_model = resnet_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dictionary of model names and checkpoint paths\nmodel_files = {\n    'Baseline CNN': ('baseline_best.h5', baseline_model),\n    'VGG16 FT': ('vgg16_transfer_model_finetuned_best.h5', vgg_model),\n    'MobileNetV2 FT': ('mobilenetv2_transfer_model_finetuned_best.h5', mob_model),\n    'EfficientNetB0 FT': ('efficientnetb0_transfer_model_finetuned_best.h5', eff0_model),\n    'ResNet50V2 FT': ('resnet50v2_transfer_model_finetuned_best.h5', resnet_model)\n}\n\nresults = {}\n\nfor name, (path, model) in model_files.items():\n    eval_model = load_model(path) if os.path.exists(path) else model\n    loss, acc = eval_model.evaluate(val_generator, verbose=0)\n    results[name] = {'loss': loss, 'accuracy': acc}\n    print(f\"{name} -> Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_name = max(results, key=lambda k: results[k]['accuracy'])\nbest_model_path = model_files[best_model_name][0]\nbest_model = load_model(best_model_path) if os.path.exists(best_model_path) else model_files[best_model_name][1]\n\nprint(f\"\\nBest model selected: {best_model_name} with accuracy {results[best_model_name]['accuracy']:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 8: Plot Training Results**","metadata":{}},{"cell_type":"code","source":"def plot_history(history, title):\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['accuracy'], label='Train')\n    plt.plot(history.history['val_accuracy'], label='Validation')\n    plt.legend(); plt.title(title + \" Accuracy\")\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'], label='Train')\n    plt.plot(history.history['val_loss'], label='Validation')\n    plt.legend(); plt.title(title + \" Loss\")\n    plt.show()\n\nplot_history(history_baseline, \"Baseline CNN\")\nplot_history(history_vgg_ft, \"VGG16\")\nplot_history(history_mob_ft, \"MobileNetV2\")\nplot_history(history_eff0_ft, \"EfficientNetB0\")\n# plot_history(history_eff3_ft, \"EfficientNetB3\")\nplot_history(history_resnet_ft, \"ResNet50V2\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 9: Summary of all models**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Convert results dict to DataFrame\ndf_results = pd.DataFrame(results).T  # transpose so models are rows\n\nprint(df_results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 10: Plot summary bars for accuracy and loss**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract data for plotting\nmodel_names = list(results.keys())\naccuracies = [results[m]['accuracy'] for m in model_names]\nlosses = [results[m]['loss'] for m in model_names]\n\n# Plot Accuracy\nplt.figure(figsize=(10,5))\nplt.bar(model_names, accuracies, color='skyblue')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)  # assuming accuracy between 0 and 1\nplt.title('Model Accuracy Comparison')\nplt.xticks(rotation=45)\nplt.show()\n\n# Plot Loss\nplt.figure(figsize=(10,5))\nplt.bar(model_names, losses, color='salmon')\nplt.ylabel('Loss')\nplt.title('Model Loss Comparison')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 11 : Compare All Models with Full Metrics**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom tensorflow.keras.models import load_model\n\ndef evaluate_model(model, val_generator, model_name, plot_roc=False):\n    \"\"\"\n    Evaluate a model and plot results, similar to previous bar chart style.\n    Stores loss and accuracy for summary comparison.\n    \"\"\"\n    # Reset generator\n    val_generator.reset()\n    steps = int(np.ceil(val_generator.samples / val_generator.batch_size))\n    \n    # Evaluate loss & accuracy\n    loss, acc = model.evaluate(val_generator, steps=steps, verbose=0)\n    \n    # Predictions\n    preds = model.predict(val_generator, steps=steps, verbose=0)\n    y_pred = np.argmax(preds, axis=1)\n    y_true = val_generator.classes\n    class_labels = list(val_generator.class_indices.keys())\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n    plt.title(f\"Confusion Matrix - {model_name}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n    \n    # Classification Report\n    print(f\"\\nClassification Report - {model_name}\")\n    print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n    \n    # ROC Curve (binary only)\n    if plot_roc and len(class_labels) == 2:\n        fpr, tpr, _ = roc_curve(y_true, preds[:, 1])\n        roc_auc = auc(fpr, tpr)\n        plt.figure(figsize=(6,5))\n        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})', color='blue')\n        plt.plot([0,1],[0,1],'k--')\n        plt.xlim([0,1])\n        plt.ylim([0,1.05])\n        plt.xlabel(\"False Positive Rate\")\n        plt.ylabel(\"True Positive Rate\")\n        plt.title(f\"ROC Curve - {model_name}\")\n        plt.legend(loc=\"lower right\")\n        plt.grid(True)\n        plt.show()\n    \n    return {'loss': loss, 'accuracy': acc}\n\n# Now evaluate all models and store in results dict (like before)\nresults = {}\n\nmodel_files = {\n    'Baseline CNN': ('baseline_best.h5', baseline_model),\n    'VGG16 FT': ('vgg16_transfer_model_finetuned_best.h5', vgg_model),\n    'MobileNetV2 FT': ('mobilenetv2_transfer_model_finetuned_best.h5', mob_model),\n    'EfficientNetB0 FT': ('efficientnetb0_transfer_model_finetuned_best.h5', eff0_model),\n    # 'EfficientNetB3 FT': ('efficientnetb3_transfer_model_finetuned_best.h5', eff3_model),\n    'ResNet50V2 FT': ('resnet50v2_transfer_model_finetuned_best.h5', resnet_model)\n}\n\nfor name, (path, model) in model_files.items():\n    eval_model = load_model(path) if os.path.exists(path) else model\n    results[name] = evaluate_model(eval_model, val_generator, name, plot_roc=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(best_model, val_generator, best_model_name, plot_roc=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 12: Grad-CAM Visualization****","metadata":{}},{"cell_type":"code","source":"def find_last_conv_layer_name(model):\n    # search top-level first, then nested submodels\n    for layer in reversed(model.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            return layer.name\n        if hasattr(layer, 'layers'):\n            for sub in reversed(layer.layers):\n                if isinstance(sub, tf.keras.layers.Conv2D):\n                    return sub.name\n    raise ValueError(\"No Conv2D layer found in the model.\")\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name=None, pred_index=None):\n    if last_conv_layer_name is None:\n        last_conv_layer_name = find_last_conv_layer_name(model)\n\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        loss = predictions[:, pred_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = tf.matmul(conv_outputs, pooled_grads[..., tf.newaxis])\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0)\n    max_val = tf.reduce_max(heatmap)\n    if max_val == 0:\n        heatmap = heatmap\n    else:\n        heatmap /= max_val\n    heatmap = heatmap.numpy()\n    heatmap = cv2.resize(heatmap, (img_width, img_height))  # cv2 expects (width, height)\n    return heatmap\n\ndef show_gradcam(model, generator, samples=3):\n    last_conv = find_last_conv_layer_name(model)\n    idxs = random.sample(range(len(generator.filenames)), min(samples, len(generator.filenames)))\n    for idx in idxs:\n        img_path = os.path.join(generator.directory, generator.filenames[idx])\n        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n        img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n        input_tensor = np.expand_dims(img_array, axis=0)\n\n        heatmap = make_gradcam_heatmap(input_tensor, model, last_conv)\n\n        heatmap_uint8 = np.uint8(255 * heatmap)\n        heatmap_col = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n        heatmap_col = cv2.cvtColor(heatmap_col, cv2.COLOR_BGR2RGB)\n\n        orig_uint8 = np.uint8(img_array * 255.0)\n        superimposed = cv2.addWeighted(orig_uint8, 0.6, heatmap_col, 0.4, 0)\n\n        plt.figure(figsize=(10,4))\n        plt.subplot(1,2,1); plt.imshow(orig_uint8); plt.title(\"Original\"); plt.axis('off')\n        plt.subplot(1,2,2); plt.imshow(superimposed); plt.title(\"Grad-CAM\"); plt.axis('off')\n        plt.show()\n\n# run Grad-CAM on the best model found\nval_generator.reset()\nshow_gradcam(best_model, val_generator, samples=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}